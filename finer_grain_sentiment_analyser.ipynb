{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NfkreWwXz-z",
        "outputId": "42796d65-58de-40d5-b401-bc1bfb052839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KCkKm90vemqL"
      },
      "outputs": [],
      "source": [
        "import random as ra\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, GRU, SpatialDropout2D\n",
        "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLIFLCp0hCPO",
        "outputId": "a92122b2-5246-4f7d-e2a8-920ced621373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cZBhJFwxhDTi"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Movie Research/yelp_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rah0JelywI6u",
        "outputId": "c1e06f81-1d5c-4906-ec30-a03ede905362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text  stars\n",
              "0        If you decide to eat here, just be aware it is...    3.0\n",
              "1        I've taken a lot of spin classes over the year...    5.0\n",
              "2        Family diner. Had the buffet. Eclectic assortm...    3.0\n",
              "3        Wow!  Yummy, different,  delicious.   Our favo...    5.0\n",
              "4        Cute interior and owner (?) gave us tour of up...    4.0\n",
              "...                                                    ...    ...\n",
              "6990275  Latest addition to services from ICCU is Apple...    5.0\n",
              "6990276  This spot offers a great, affordable east week...    5.0\n",
              "6990277  This Home Depot won me over when I needed to g...    4.0\n",
              "6990278  For when I'm feeling like ignoring my calorie-...    5.0\n",
              "6990279  Located in the 'Walking District' in Nashville...    3.0\n",
              "\n",
              "[6990280 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7b4a2a5b-9a4c-48b9-bd46-22a3c2a274da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If you decide to eat here, just be aware it is...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I've taken a lot of spin classes over the year...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990275</th>\n",
              "      <td>Latest addition to services from ICCU is Apple...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990276</th>\n",
              "      <td>This spot offers a great, affordable east week...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990277</th>\n",
              "      <td>This Home Depot won me over when I needed to g...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990278</th>\n",
              "      <td>For when I'm feeling like ignoring my calorie-...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990279</th>\n",
              "      <td>Located in the 'Walking District' in Nashville...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6990280 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b4a2a5b-9a4c-48b9-bd46-22a3c2a274da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-798562b7-53b9-4b66-8e42-870591a6187d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-798562b7-53b9-4b66-8e42-870591a6187d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-798562b7-53b9-4b66-8e42-870591a6187d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b4a2a5b-9a4c-48b9-bd46-22a3c2a274da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b4a2a5b-9a4c-48b9-bd46-22a3c2a274da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R3s9RuEghn6i"
      },
      "outputs": [],
      "source": [
        "temp = data.sample(n = 350000, random_state=42)\n",
        "df = temp.sample(frac = .1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0sf00GAjLBC",
        "outputId": "0cdb0190-d5e4-49ad-ac0e-576df75f235c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o80l5agDin8P"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ7B1pvdipqz",
        "outputId": "8ea84c4c-4eb3-49f9-f55d-cf8e8bb426fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uRck8272j4D_"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jW0OIAXfj6Qj"
      },
      "outputs": [],
      "source": [
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xkHC9E-Ij7-c"
      },
      "outputs": [],
      "source": [
        "# df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J2nXUNIXkGGE"
      },
      "outputs": [],
      "source": [
        "# df['text'] = df['text'].str.replace('[^\\w\\s]', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T7YGPjRakHix"
      },
      "outputs": [],
      "source": [
        "# Apply the remove_stopwords and lemmatize_text functions to the 'text' column\n",
        "# df['text'] = df['text'].apply(remove_stopwords)\n",
        "# df['text'] = df['text'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "znpR9iHhkJa9"
      },
      "outputs": [],
      "source": [
        "# train_df = df[:27000]\n",
        "# test_df = df[27000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BMgNEIjFkLFy"
      },
      "outputs": [],
      "source": [
        "# max_features = 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MTHco1-OkMdc"
      },
      "outputs": [],
      "source": [
        "# # Tokenization\n",
        "# tokenizer = Tokenizer(num_words=max_features)\n",
        "# tokenizer.fit_on_texts(list(train_df['text'].values))\n",
        "# X_train = tokenizer.texts_to_sequences(train_df['text'].values)\n",
        "# X_test = tokenizer.texts_to_sequences(test_df['text'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PzTDfOzvkz-p"
      },
      "outputs": [],
      "source": [
        "# x_train = pad_sequences(X_train, maxlen=200)\n",
        "# x_test = pad_sequences(X_test, maxlen=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9HfQVLyVloKc"
      },
      "outputs": [],
      "source": [
        "# word_index = tokenizer.word_index\n",
        "# nb_words = min(max_features, len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_mUIHSeIlpjv"
      },
      "outputs": [],
      "source": [
        "# embedding_matrix = np.zeros((nb_words, 200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hVDfOD5vlqxy"
      },
      "outputs": [],
      "source": [
        "# embedding_file = '/content/drive/MyDrive/Movie Research/glove.twitter.27B.200d.txt'\n",
        "\n",
        "# read in embeddings\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "# embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embedding_file, 'r', encoding = 'utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92doXnhFnUig"
      },
      "outputs": [],
      "source": [
        "# word_index = tokenizer.word_index\n",
        "# nb_words = min(max_features, len(word_index))\n",
        "\n",
        "# embedding_matrix = np.zeros((nb_words, 200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox5mC6eMnXZ1"
      },
      "outputs": [],
      "source": [
        "# missed = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHa2dhTJpxtv"
      },
      "outputs": [],
      "source": [
        "# for word, i in word_index.items():\n",
        "\n",
        "#     if i == max_features:\n",
        "#         break\n",
        "\n",
        "#     embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "#     if embedding_vector is not None:\n",
        "#         embedding_matrix[i] = embedding_vector\n",
        "#     else:\n",
        "#         missed.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "def get_tokenizer(df):\n",
        "  # Tokenization\n",
        "  global max_features\n",
        "  tokenizer = Tokenizer(num_words=max_features)\n",
        "  tokenizer.fit_on_texts(list(df['text'].values))\n",
        "  return tokenizer\n",
        "\n",
        "def preprocess_dataframe(tokenizer, df, maxlen=200):\n",
        "  df['text'] = df['text'].str.lower()\n",
        "  df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
        "  # Apply the remove_stopwords and lemmatize_text functions to the 'text' column\n",
        "  df['text'] = df['text'].apply(remove_stopwords)\n",
        "  df['text'] = df['text'].apply(lemmatize_text)\n",
        "  X = tokenizer.texts_to_sequences(df['text'].values)\n",
        "  x = pad_sequences(X, maxlen=maxlen)\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "xxVLI7v-Nt_v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_file = '/content/drive/MyDrive/Movie Research/glove.twitter.27B.200d.txt'\n",
        "def get_embedding_matrix(tokenizer):\n",
        "  global embedding_file\n",
        "  word_index = tokenizer.word_index\n",
        "  nb_words = min(max_features, len(word_index))\n",
        "  embedding_matrix = np.zeros((nb_words, 200))\n",
        "  embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embedding_file, 'r', encoding = 'utf-8'))\n",
        "  missed = []\n",
        "  for word, i in word_index.items():\n",
        "\n",
        "    if i == max_features:\n",
        "        break\n",
        "\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        missed.append(word)\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "H5LYCoo7Qnqh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, df):\n",
        "  x = preprocess_dataframe(df)\n",
        "  return model.predict(x)"
      ],
      "metadata": {
        "id": "SS2Q-PRTOwCm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xEbo47zvssQT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "def check_params(units, spatial_dropout_rate, batch_size, count):\n",
        "  global df\n",
        "  inp = Input(shape = (200,))\n",
        "  tokenizer = get_tokenizer(df)\n",
        "  embedding_matrix = get_embedding_matrix(tokenizer)\n",
        "  x = Embedding(max_features, 200, weights = [embedding_matrix], trainable = True)(inp)\n",
        "  x = SpatialDropout1D(spatial_dropout_rate)(x)\n",
        "  x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "  x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
        "  x = Bidirectional(GRU(units, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, max_pool])\n",
        "  outp = Dense(5, activation = 'sigmoid')(conc)\n",
        "\n",
        "  model = Model(inputs = inp, outputs = outp)\n",
        "  # patience is how many epochs to wait to see if val_loss will improve again.\n",
        "  earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3)\n",
        "  checkpoint = ModelCheckpoint(monitor = 'val_loss', save_best_only = True, filepath = f'./models/yelp_lstm_gru_weights_{count}.hdf5')\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "  train_df = df[:27000]\n",
        "  x_train = preprocess_dataframe(tokenizer, train_df)\n",
        "  y_train = pd.get_dummies(train_df['stars'])\n",
        "\n",
        "  history = model.fit(x_train, y_train, batch_size = batch_size, epochs = 10, validation_split = .2,\n",
        "          callbacks=[earlystop, checkpoint])\n",
        "\n",
        "  return history.history['accuracy']\n",
        "\n",
        "def generate_random_number(x):\n",
        "  return ra.randint(0,x-1)\n",
        "\n",
        "def train_model_random_search(model_count):\n",
        "  param_grid = {\n",
        "      'units': [30, 60, 90],\n",
        "      'spatial_dropout_rate': [0.3, 0.5],\n",
        "      'batch_size': [256,512]\n",
        "  }\n",
        "\n",
        "  config_list = []\n",
        "\n",
        "  for i in range(model_count):\n",
        "    units = param_grid['units'][generate_random_number(len(param_grid['units']))]\n",
        "    spatial_dropout_rate = param_grid['spatial_dropout_rate'][generate_random_number(len(param_grid['spatial_dropout_rate']))]\n",
        "    batch_size = param_grid['batch_size'][generate_random_number(len(param_grid['batch_size']))]\n",
        "    config_list.append((units,spatial_dropout_rate,batch_size))\n",
        "\n",
        "    if((units,spatial_dropout_rate,batch_size) in config_list):\n",
        "      --i\n",
        "\n",
        "  results = dict()\n",
        "\n",
        "  count = 0\n",
        "  for i in config_list:\n",
        "    count+=1\n",
        "    results[i] = check_params(i[0], i[1], i[2], count)\n",
        "\n",
        "\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRu5TvIgxPZE",
        "outputId": "5e6c7669-0f32-447d-b5d5-8bcea374c7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-366570351d34>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.lower()\n",
            "<ipython-input-22-366570351d34>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-22-366570351d34>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-22-366570351d34>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_stopwords)\n",
            "<ipython-input-22-366570351d34>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(lemmatize_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "43/43 [==============================] - 666s 15s/step - loss: 0.4794 - accuracy: 0.4510 - val_loss: 0.4333 - val_accuracy: 0.4709\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 635s 15s/step - loss: 0.3794 - accuracy: 0.5442 - val_loss: 0.3371 - val_accuracy: 0.5952\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 632s 15s/step - loss: 0.3120 - accuracy: 0.6236 - val_loss: 0.3314 - val_accuracy: 0.6143\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 634s 15s/step - loss: 0.2778 - accuracy: 0.6753 - val_loss: 0.3033 - val_accuracy: 0.6400\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 650s 15s/step - loss: 0.2365 - accuracy: 0.7363 - val_loss: 0.3087 - val_accuracy: 0.6469\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 630s 15s/step - loss: 0.2051 - accuracy: 0.7812 - val_loss: 0.3302 - val_accuracy: 0.6259\n",
            "Epoch 7/10\n",
            "43/43 [==============================] - 638s 15s/step - loss: 0.1789 - accuracy: 0.8183 - val_loss: 0.3544 - val_accuracy: 0.6093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-366570351d34>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.lower()\n",
            "<ipython-input-22-366570351d34>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-22-366570351d34>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-22-366570351d34>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(remove_stopwords)\n",
            "<ipython-input-22-366570351d34>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text'] = df['text'].apply(lemmatize_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "85/85 [==============================] - 665s 8s/step - loss: 0.4334 - accuracy: 0.4887 - val_loss: 0.3368 - val_accuracy: 0.5994\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 678s 8s/step - loss: 0.3087 - accuracy: 0.6273 - val_loss: 0.2948 - val_accuracy: 0.6583\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 679s 8s/step - loss: 0.2560 - accuracy: 0.7036 - val_loss: 0.2966 - val_accuracy: 0.6567\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 685s 8s/step - loss: 0.2253 - accuracy: 0.7473 - val_loss: 0.3032 - val_accuracy: 0.6435\n",
            "Epoch 5/10\n",
            "47/85 [===============>..............] - ETA: 4:28 - loss: 0.1964 - accuracy: 0.7896"
          ]
        }
      ],
      "source": [
        "train_model_random_search(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y_Ki9gXp069"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "# inp = Input(shape = (200,))\n",
        "# x = Embedding(max_features, 200, weights = [embedding_matrix], trainable = True)(inp)\n",
        "# x = SpatialDropout1D(0.3)(x)\n",
        "# # x = SpatialDropout2D(0.3)(x)\n",
        "# x = Bidirectional(LSTM(60, return_sequences=True))(x)\n",
        "# x = Bidirectional(LSTM(60, return_sequences=True))(x)\n",
        "# x = Bidirectional(GRU(60, return_sequences=True))(x)\n",
        "# avg_pool = GlobalAveragePooling1D()(x)\n",
        "# max_pool = GlobalMaxPooling1D()(x)\n",
        "# conc = concatenate([avg_pool, max_pool])\n",
        "# outp = Dense(5, activation = 'sigmoid')(conc)\n",
        "\n",
        "# model = Model(inputs = inp, outputs = outp)\n",
        "# # patience is how many epochs to wait to see if val_loss will improve again.\n",
        "# earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3)\n",
        "# checkpoint = ModelCheckpoint(monitor = 'val_loss', save_best_only = True, filepath = 'yelp_lstm_gru_weights.hdf5')\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "# y_train = pd.get_dummies(train_df[\"stars\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Di4phJ2p9pR"
      },
      "outputs": [],
      "source": [
        "# model = Model(inputs = inp, outputs = outp)\n",
        "# # patience is how many epochs to wait to see if val_loss will improve again.\n",
        "\n",
        "# earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3)\n",
        "# checkpoint = ModelCheckpoint(monitor = 'val_loss', save_best_only = True, filepath = 'yelp_lstm_gru_weights.hdf5')\n",
        "# model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfxX8-wPqABu"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, batch_size = 256, epochs = 10, validation_split = .1,\n",
        "          callbacks=[earlystop, checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDKPWZl2qB4R"
      },
      "outputs": [],
      "source": [
        "model.save('saved_model/sentiment_analyzer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cEnN-zfxsu4"
      },
      "outputs": [],
      "source": [
        "store = tf.keras.models.load_model('saved_model/sentiment_analyzer')\n",
        "store.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E07R6z_Mx2vJ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP5KpvH6Edp3"
      },
      "outputs": [],
      "source": [
        "model = model.load('./models/yelp_lstm_gru_weights_1.hdf5')\n",
        "test_df = df[27000:]\n",
        "make_predictions(model, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDKXyoOZVFFb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgzCgueUcHP4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}